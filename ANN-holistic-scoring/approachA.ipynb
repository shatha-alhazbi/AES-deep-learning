{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **READ_ME**\n",
        "\n",
        "# Model Configuration Guide\n",
        "\n",
        "this explains how to configure the neural network model for different target prompt when training and evaluating essay scoring models.\n",
        "\n",
        "## Key Configuration Variables\n",
        "There are 4 main variables that control which prompts are used for different stages of the model:\n",
        "\n",
        "1. `TEST_PROMPT_ID`: the taget prompt held out for final testing (section 1.4)\n",
        "2. `TRAIN_PROMPT_RANGE`: list of prompts used in grid search  (section 1.4)\n",
        "3. `VALIDATION_PROMPT_ID`: use any training prompt that isnt the test promp (section 1.6)\n",
        "4. `ranges`: list of prompts used for batch optimization (section 1.6)\n",
        "\n",
        "### Default Configuration (Here target prompt = 2)\n",
        "\n",
        "```python\n",
        "TEST_PROMPT_ID = 2\n",
        "TRAIN_PROMPT_RANGE = [1,3,4,5,6,7,8]\n",
        "VALIDATION_PROMPT_ID = 8\n",
        "ranges = [1,3,4,5,6,7]\n",
        "```\n",
        "\n",
        "## How to Modify\n",
        "\n",
        "### Step 1: Choose Test Prompt\n",
        "```python\n",
        "TEST_PROMPT_ID = 2  #change to any prompt id you want to test on/target\n",
        "```\n",
        "This prompt will be completely held out until final evaluation.\n",
        "\n",
        "### Step 2: Set Training Range\n",
        "```python\n",
        "TRAIN_PROMPT_RANGE = [1,3,4,5,6,7,8]  #(all prompts except test prompt\n",
        "```\n",
        "- remove the `TEST_PROMPT_ID` from this list\n",
        "- its used during grid search to find optimal hyperparameters\n",
        "- example: If `TEST_PROMPT_ID = 1`, then use `TRAIN_PROMPT_RANGE = [2,3,4,5,6,7,8]`\n",
        "\n",
        "### Step 3: Set Validation Prompt\n",
        "\n",
        "```python\n",
        "VALIDATION_PROMPT_ID = 8  #change to desired validation prompt\n",
        "```\n",
        "- used during batch size optimization (since our data is divided 6 prompts testing 1 prompt validation, we let the validation be a manually entered prompt)\n",
        "- should be one of the prompts from `TRAIN_PROMPT_RANGE`\n",
        "\n",
        "### Step 4: Update Training Ranges\n",
        "```python\n",
        "ranges = [1,3,4,5,6,7]  #remove both test and validation prompts\n",
        "```\n",
        "- remove both `TEST_PROMPT_ID` and `VALIDATION_PROMPT_ID`\n",
        "- used for batch optimization\n",
        "- Example: If `TEST_PROMPT_ID = 1` and `VALIDATION_PROMPT_ID = 8`, then use `ranges = [2,3,4,5,6,7]`\n",
        "\n",
        "## Example\n",
        "\n",
        "### Configuration 1: Testing on Prompt 1\n",
        "```python\n",
        "TEST_PROMPT_ID = 1\n",
        "TRAIN_PROMPT_RANGE = [2,3,4,5,6,7,8]\n",
        "VALIDATION_PROMPT_ID = 8\n",
        "ranges = [2,3,4,5,6,7]\n",
        "```\n",
        "\n",
        "\n",
        "## Important Notes\n",
        "\n",
        "1. Make sure:\n",
        "   - test prompt should not appear in any other list\n",
        "   - validation prompt should be in `TRAIN_PROMPT_RANGE` but not in `ranges`\n",
        "   - all remaining prompts should be in both `TRAIN_PROMPT_RANGE` and `ranges`\n",
        "\n",
        "2. The model uses these splits for:\n",
        "   - grid Search: Uses `TRAIN_PROMPT_RANGE` for cross-validation\n",
        "   - batch Size Optimization: Uses `ranges` for training and `VALIDATION_PROMPT_ID` for validation\n",
        "   - final Training: Uses all prompts except `TEST_PROMPT_ID` for training, then evaluates on `TEST_PROMPT_ID`\n",
        "\n",
        "3. The model saves the final trained model as \"model-A-{TEST_PROMPT_ID}.pt\""
      ],
      "metadata": {
        "id": "6domm4YYDDSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Approach A: Holistic Scoring using FNN"
      ],
      "metadata": {
        "id": "RTUPfTTBtTus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOvOVm8ItKvX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import time\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Starter Code"
      ],
      "metadata": {
        "id": "spMAItVmtkgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SCORE_RANGES = {\n",
        "        1: {'sentence_fluency': (1, 6), 'word_choice': (1, 6), 'conventions': (1, 6),'organization': (1, 6),\n",
        "            'content': (1, 6), 'holistic': (2, 12)},\n",
        "        2: {'sentence_fluency': (1, 6), 'word_choice': (1, 6), 'conventions': (1, 6),'organization': (1, 6),\n",
        "            'content': (1, 6), 'holistic': (1, 6)},\n",
        "        3: {'narrativity': (0, 3), 'language': (0, 3), 'prompt_adherence': (0, 3), 'content': (0, 3), 'holistic': (0, 3)},\n",
        "        4: {'narrativity': (0, 3), 'language': (0, 3), 'prompt_adherence': (0, 3), 'content': (0, 3), 'holistic': (0, 3)},\n",
        "        5: {'narrativity': (0, 4), 'language': (0, 4), 'prompt_adherence': (0, 4), 'content': (0, 4), 'holistic': (0, 4)},\n",
        "        6: {'narrativity': (0, 4), 'language': (0, 4), 'prompt_adherence': (0, 4), 'content': (0, 4), 'holistic': (0, 4)},\n",
        "        7: {'conventions': (0, 6), 'organization': (0, 6), 'content': (0, 6),'holistic': (0, 30)},\n",
        "        8: {'sentence_fluency': (2, 12), 'word_choice': (2, 12), 'conventions': (2, 12),'organization': (2, 12),\n",
        "            'content': (2, 12), 'holistic': (0, 60)}}\n",
        "\n",
        "def read_data(path):\n",
        "    \"\"\"\n",
        "    Reads the CSV file and returns a dictionary that has parallel lists of values.\n",
        "\n",
        "    Parameters:\n",
        "    - path (str): Path to the CSV file containing the essay data.\n",
        "\n",
        "    Returns: data_dict (dict): A dictionary that has parallel lists, with the following keys:\n",
        "        - 'essay_ids': Unique identifiers for each essay\n",
        "        - 'prompt_ids': Identifiers for the prompt id\n",
        "        - 'essay_text': Text contents of the essays\n",
        "        - 'features': The 86 extracted features extracted from the essays\n",
        "        - 'holistic': Holistic scores\n",
        "        - 'content': Content scores\n",
        "        - 'organization': Organization scores\n",
        "        - 'word_choice': Word choice scores\n",
        "        - 'sentence_fluency': Sentence fluency scores\n",
        "        - 'conventions': Conventions scores\n",
        "        - 'prompt_adherence': Prompt adherence scores\n",
        "        - 'language': Language scores\n",
        "        - 'narrativity': Narrativity scores\n",
        "    \"\"\"\n",
        "\n",
        "    data = pd.read_csv(path)\n",
        "    data_dict = {\n",
        "        'essay_ids': data['essay_id'].values,\n",
        "        'prompt_ids': data['prompt_id'].values,\n",
        "        'essay_text': data['essay_text'].values,\n",
        "        'features': data.iloc[:, 12:].values,\n",
        "        'holistic':data['holistic'].values,\n",
        "        'content':data['content'].values,\n",
        "        'organization':data['organization'].values,\n",
        "        'word_choice':data['word_choice'].values,\n",
        "        'sentence_fluency':data['sentence_fluency'].values,\n",
        "        'conventions':data['conventions'].values,\n",
        "        'prompt_adherence':data['prompt_adherence'].values,\n",
        "        'language':data['language'].values,\n",
        "        'narrativity':data['narrativity'].values\n",
        "    }\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "def quadratic_weighted_kappa(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the Quadratic Weighted Kappa (QWK) score between true labels and predictions using sklearn.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (array-like): The true labels\n",
        "    - y_pred (array-like): The predicted labels\n",
        "\n",
        "    Returns:\n",
        "    - float: The QWK score between y_true and y_pred.\n",
        "    \"\"\"\n",
        "    return cohen_kappa_score(y_true, np.round(y_pred), weights='quadratic')"
      ],
      "metadata": {
        "id": "Lj4cSi4Ntttl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Defining the NN class"
      ],
      "metadata": {
        "id": "IgLcEmfAtyeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_unit, num_layers):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        #input layer and activaition\n",
        "        layers.append(nn.Linear(input_size, hidden_unit))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        #hidden layers depending on num of layers we are trying\n",
        "        for i in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_unit, hidden_unit))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        layers.append(nn.Linear(hidden_unit, 1)) #the output layer\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "        for i in self.modules():\n",
        "            if isinstance(i, nn.Linear): #make sure we only initialise in the liear layers and not the activiation layer\n",
        "                nn.init.kaiming_normal_(i.weight) #initialize weights using he initialization\n",
        "                nn.init.zeros_(i.bias) #set biases to 0s\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "WlhW3kpruWx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Helper Normalization Functions"
      ],
      "metadata": {
        "id": "X8t39eQXv4RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_scores(scores, prompt_id):\n",
        "   #get the min and max score ranges for specified prompt\n",
        "    score_range = SCORE_RANGES[prompt_id]['holistic']\n",
        "    return (scores - score_range[0]) / (score_range[1] - score_range[0]) #scale it between 0 and 1\n",
        "\n",
        "def denormalize_scores(norm_scores, prompt_id):\n",
        "     #get the min and max score ranges for specified prompt\n",
        "    score_range = SCORE_RANGES[prompt_id]['holistic']\n",
        "    return norm_scores * (score_range[1] - score_range[0]) + score_range[0] #get the original score back for descaling later"
      ],
      "metadata": {
        "id": "D7YgX5BxwJDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Data Initialization"
      ],
      "metadata": {
        "id": "N75_K2L-wJ76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the target prompt and the train prompts"
      ],
      "metadata": {
        "id": "PahTvY7fDYDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_PROMPT_ID = 2\n",
        "TRAIN_PROMPT_RANGE = [1,3,4,5,6,7,8]"
      ],
      "metadata": {
        "id": "VHaK8TWmjwGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'-'*50}\")\n",
        "print(f\"starting training process at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"{'-'*50}\\n\")\n",
        "\n",
        "print(\"reading the dataset\\n\")\n",
        "data = read_data('dataset.csv')\n",
        "\n",
        "filter = data['prompt_ids'] != TEST_PROMPT_ID #returns true for all prompts that are not the test prompt\n",
        "prompt_ids = data['prompt_ids'][filter] #returns prompt_ids that are true (not the first one)\n",
        "features = torch.FloatTensor(data['features'][filter]) #returns the features for prompt_ids that are true\n",
        "scores = torch.FloatTensor(data['holistic'][filter]) #returns the holistic scores for prompt_ids that are true\n",
        "\n",
        "print(f\"feature shape: {features.shape}\") #to see how many examples and features we have\n",
        "\n",
        "normalized_scores = torch.zeros_like(scores)\n",
        "for prompt_id in TRAIN_PROMPT_RANGE:\n",
        "    prompt_filter = prompt_ids == prompt_id #true when equal to the current prompt id\n",
        "    normalized_scores[prompt_filter] = normalize_scores(scores[prompt_filter], prompt_id) #normalize scores for that prompt id based on its range\n",
        "normalized_scores = normalized_scores.reshape(-1, 1) #reshape to column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KBiOss1qqz",
        "outputId": "68a06f0f-e819-481c-b2ce-834518285a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "starting training process at 2024-11-19 14:37:40\n",
            "--------------------------------------------------\n",
            "\n",
            "reading the dataset\n",
            "\n",
            "feature shape: torch.Size([11178, 86])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Grid Search using k-fold cv"
      ],
      "metadata": {
        "id": "WToJ8iFM4kvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will do 7-fold cross validation for hyper parameter tuning\n",
        "prompts = TRAIN_PROMPT_RANGE\n",
        "k_fold = KFold(n_splits=7, shuffle=False) #shuffle = false because each prompt will have a seperate fold, not random\n",
        "#------------------------ Grid Search Params ---------------------------\n",
        "hidden_units = [8, 16, 32]\n",
        "num_layers_options = [1, 2, 4, 8]\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_size = 4  #its fixed at this stage\n",
        "\n",
        "total_combinations = len(hidden_units) * len(num_layers_options) * len(learning_rates)\n",
        "print(f\"\\nStarting grid search with {total_combinations} combinations\")\n",
        "print(f\"- hidden units per layer (D): {hidden_units}\")\n",
        "print(f\"- num of layers (k): {num_layers_options}\")\n",
        "print(f\"- learning rates: {learning_rates}\")\n",
        "print(f\"- batch size (fixed): {batch_size}\\n\")\n",
        "#-----------------------------------------------------------------------\n",
        "best_qwk = -1 #initialize best qwk as lowest value (QWK is from [-1,1])\n",
        "best_params = None\n",
        "combination_count = 0\n",
        "start_time = time.time()\n",
        "#starting the grid search for combinations of hyperparams\n",
        "for hidden_unit in hidden_units:\n",
        "    for num_layers in num_layers_options:\n",
        "        for lr in learning_rates:\n",
        "            combination_count += 1 #keep count of the combination number\n",
        "            print(f\"\\n--------------- testing combination {combination_count}/{total_combinations}--------------\")\n",
        "            print(f\"hyperparams: units per layer D={hidden_unit}, num of layers k={num_layers}, lr={lr}\")\n",
        "\n",
        "            fold_qwks = [] #list to store QWK score for each model/fold\n",
        "            fold_start_time = time.time()\n",
        "\n",
        "            #start the 7 fold cv\n",
        "            for fold, (train_prompt_idx, val_prompt_idx) in enumerate(k_fold.split(prompts)):\n",
        "                #get training and validation prompts for current model\n",
        "                train_prompts = [prompts[i] for i in train_prompt_idx]\n",
        "                val_prompt = prompts[val_prompt_idx[0]]\n",
        "                print(f\"\\nvalidation prompt {val_prompt}:\", end=\" \", flush=True)\n",
        "\n",
        "                #create a filter for selecting training and validation data based on prompts\n",
        "                train_filter = np.isin(prompt_ids, train_prompts)\n",
        "                val_filter = (prompt_ids == val_prompt)\n",
        "\n",
        "                #split\n",
        "                X_train, X_val = features[train_filter], features[val_filter]\n",
        "                y_train, y_val = normalized_scores[train_filter], normalized_scores[val_filter]\n",
        "\n",
        "                #initialize model with hyper param combo\n",
        "                model = NeuralNetwork(86, hidden_unit, num_layers)\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0.1)\n",
        "                criterion = nn.MSELoss()\n",
        "\n",
        "                #start training for max epochs 15 with early stopping\n",
        "                best_val_loss = float('inf') #loss at huge number, \"infinity\" to start\n",
        "                epochs_no_improve = 0\n",
        "\n",
        "                for epoch in range(15):  #max epochs = 15\n",
        "                    model.train()\n",
        "                    epoch_loss = 0\n",
        "                    num_batches = 0\n",
        "\n",
        "                    #update for batch\n",
        "                    for i in range(0, len(X_train), batch_size):\n",
        "                        batch_X = X_train[i:i + batch_size]\n",
        "                        batch_y = y_train[i:i + batch_size]\n",
        "\n",
        "                        optimizer.zero_grad() #reset gradients\n",
        "                        outputs = model(batch_X) #model forward pass\n",
        "                        loss = criterion(outputs, batch_y) #compute loss\n",
        "                        loss.backward() #backpropagation\n",
        "                        optimizer.step() #update model params\n",
        "\n",
        "                        epoch_loss += loss.item() #accumulate loss per epoch\n",
        "                        num_batches += 1\n",
        "                    avg_epoch_loss = epoch_loss / num_batches #calculate average loss for current epoch\n",
        "\n",
        "                    #------------------------ EARLY STOPPING --------------------------------------\n",
        "                    #see if training loss is improving, if it isnt, do early stopping\n",
        "                    if avg_epoch_loss < best_val_loss:\n",
        "                        best_val_loss = avg_epoch_loss\n",
        "                        epochs_no_improve = 0\n",
        "                    else:\n",
        "                        epochs_no_improve += 1\n",
        "\n",
        "                    if epochs_no_improve >= 3:  # Early stopping threshold\n",
        "                        print(f\"early stop at epoch {epoch + 1}\", end=\" \")\n",
        "                        break\n",
        "\n",
        "                  #---------------------------------------------------------------------------------\n",
        "\n",
        "                #validate the fold\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_pred = model(X_val)\n",
        "                    val_pred_denorm = denormalize_scores(val_pred.numpy(), val_prompt)\n",
        "                    val_true_denorm = denormalize_scores(y_val.numpy(), val_prompt)\n",
        "                    fold_qwk = quadratic_weighted_kappa(\n",
        "                        val_true_denorm.round().flatten(),\n",
        "                        val_pred_denorm.flatten()\n",
        "                    )\n",
        "                    fold_qwks.append(fold_qwk)\n",
        "                    print(f\"QWK: {fold_qwk:.4f}\")\n",
        "\n",
        "            #calculate average qwk across all folds of current combo\n",
        "            avg_qwk = np.mean(fold_qwks)\n",
        "            fold_time = time.time() - fold_start_time\n",
        "            print(f\"\\nAverage QWK for this combination: {avg_qwk:.4f}\")\n",
        "            #------------------------ UPDATE BEST HYPERPARAM -------------------\n",
        "            #update the best hyperparams if this combination performs better\n",
        "            if avg_qwk > best_qwk:\n",
        "                best_qwk = avg_qwk\n",
        "                best_params = {\n",
        "                    'hidden_unit': hidden_unit,\n",
        "                    'num_layers': num_layers,\n",
        "                    'learning_rate': lr\n",
        "                }\n",
        "                print(f\"BEST COMBO SO FAR! =)\")\n",
        "            #--------------------------------------------------------------------\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n{'-'*50}\")\n",
        "print(\"---------------- FINISHED GRID SEARCH ----------------\")\n",
        "print(f\"mins taken:({total_time/60:.2f} mins)\")\n",
        "print(f\"best hyperparam combo: {best_params} with best average QWK: {best_qwk:.4f}\")\n",
        "print(f\"{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftOVoN3x1rdj",
        "outputId": "df4621a3-eb2e-450d-981b-1def73f7109a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting grid search with 36 combinations\n",
            "- hidden units per layer (D): [8, 16, 32]\n",
            "- num of layers (k): [1, 2, 4, 8]\n",
            "- learning rates: [0.001, 0.01, 0.1]\n",
            "- batch size (fixed): 4\n",
            "\n",
            "\n",
            "--------------- testing combination 1/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=1, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4439\n",
            "\n",
            "validation prompt 3: QWK: 0.4940\n",
            "\n",
            "validation prompt 4: QWK: 0.5224\n",
            "\n",
            "validation prompt 5: QWK: 0.3136\n",
            "\n",
            "validation prompt 6: QWK: 0.1217\n",
            "\n",
            "validation prompt 7: QWK: 0.5566\n",
            "\n",
            "validation prompt 8: early stop at epoch 13 QWK: 0.3475\n",
            "\n",
            "Average QWK for this combination: 0.3999\n",
            "BEST COMBO SO FAR! =)\n",
            "\n",
            "--------------- testing combination 2/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=1, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 9 QWK: 0.3329\n",
            "\n",
            "validation prompt 3: early stop at epoch 6 QWK: 0.4185\n",
            "\n",
            "validation prompt 4: early stop at epoch 6 QWK: 0.4609\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0860\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0299\n",
            "\n",
            "validation prompt 7: QWK: 0.3257\n",
            "\n",
            "validation prompt 8: early stop at epoch 6 QWK: 0.4344\n",
            "\n",
            "Average QWK for this combination: 0.2984\n",
            "\n",
            "--------------- testing combination 3/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=1, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 4/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=2, lr=0.001\n",
            "\n",
            "validation prompt 1: early stop at epoch 12 QWK: 0.4458\n",
            "\n",
            "validation prompt 3: QWK: 0.5106\n",
            "\n",
            "validation prompt 4: QWK: 0.5487\n",
            "\n",
            "validation prompt 5: early stop at epoch 10 QWK: 0.2781\n",
            "\n",
            "validation prompt 6: QWK: 0.1531\n",
            "\n",
            "validation prompt 7: QWK: 0.4540\n",
            "\n",
            "validation prompt 8: early stop at epoch 14 QWK: 0.4215\n",
            "\n",
            "Average QWK for this combination: 0.4017\n",
            "BEST COMBO SO FAR! =)\n",
            "\n",
            "--------------- testing combination 5/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=2, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 6 QWK: 0.3631\n",
            "\n",
            "validation prompt 3: early stop at epoch 7 QWK: 0.4655\n",
            "\n",
            "validation prompt 4: early stop at epoch 7 QWK: 0.4953\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0398\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0182\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.3385\n",
            "\n",
            "validation prompt 8: early stop at epoch 7 QWK: 0.4337\n",
            "\n",
            "Average QWK for this combination: 0.3077\n",
            "\n",
            "--------------- testing combination 6/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=2, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 7/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=4, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.5013\n",
            "\n",
            "validation prompt 3: early stop at epoch 12 QWK: 0.5089\n",
            "\n",
            "validation prompt 4: QWK: 0.5438\n",
            "\n",
            "validation prompt 5: early stop at epoch 8 QWK: 0.2669\n",
            "\n",
            "validation prompt 6: QWK: 0.1553\n",
            "\n",
            "validation prompt 7: QWK: 0.5436\n",
            "\n",
            "validation prompt 8: early stop at epoch 14 QWK: 0.3938\n",
            "\n",
            "Average QWK for this combination: 0.4162\n",
            "BEST COMBO SO FAR! =)\n",
            "\n",
            "--------------- testing combination 8/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=4, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.3542\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.4987\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.5560\n",
            "\n",
            "validation prompt 5: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 7 QWK: 0.0347\n",
            "\n",
            "validation prompt 7: early stop at epoch 8 QWK: 0.3377\n",
            "\n",
            "validation prompt 8: early stop at epoch 8 QWK: 0.5118\n",
            "\n",
            "Average QWK for this combination: 0.3276\n",
            "\n",
            "--------------- testing combination 9/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=4, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 10/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=8, lr=0.001\n",
            "\n",
            "validation prompt 1: early stop at epoch 14 QWK: 0.4737\n",
            "\n",
            "validation prompt 3: QWK: 0.5123\n",
            "\n",
            "validation prompt 4: early stop at epoch 13 QWK: 0.3745\n",
            "\n",
            "validation prompt 5: early stop at epoch 14 QWK: 0.2056\n",
            "\n",
            "validation prompt 6: QWK: 0.1280\n",
            "\n",
            "validation prompt 7: QWK: 0.5136\n",
            "\n",
            "validation prompt 8: QWK: 0.4367\n",
            "\n",
            "Average QWK for this combination: 0.3778\n",
            "\n",
            "--------------- testing combination 11/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=8, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.3599\n",
            "\n",
            "validation prompt 3: early stop at epoch 6 QWK: 0.5068\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 6 QWK: 0.0550\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0133\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.3423\n",
            "\n",
            "validation prompt 8: early stop at epoch 6 QWK: 0.6061\n",
            "\n",
            "Average QWK for this combination: 0.2691\n",
            "\n",
            "--------------- testing combination 12/36--------------\n",
            "hyperparams: units per layer D=8, num of layers k=8, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 13/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=1, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4148\n",
            "\n",
            "validation prompt 3: early stop at epoch 13 QWK: 0.4921\n",
            "\n",
            "validation prompt 4: early stop at epoch 8 QWK: 0.5078\n",
            "\n",
            "validation prompt 5: early stop at epoch 15 QWK: 0.2938\n",
            "\n",
            "validation prompt 6: QWK: 0.1296\n",
            "\n",
            "validation prompt 7: early stop at epoch 14 QWK: 0.5649\n",
            "\n",
            "validation prompt 8: QWK: 0.4136\n",
            "\n",
            "Average QWK for this combination: 0.4024\n",
            "\n",
            "--------------- testing combination 14/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=1, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 9 QWK: 0.3329\n",
            "\n",
            "validation prompt 3: early stop at epoch 10 QWK: 0.4185\n",
            "\n",
            "validation prompt 4: early stop at epoch 6 QWK: 0.4609\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0860\n",
            "\n",
            "validation prompt 6: early stop at epoch 9 QWK: 0.0299\n",
            "\n",
            "validation prompt 7: early stop at epoch 10 QWK: 0.3257\n",
            "\n",
            "validation prompt 8: early stop at epoch 6 QWK: 0.4344\n",
            "\n",
            "Average QWK for this combination: 0.2984\n",
            "\n",
            "--------------- testing combination 15/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=1, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 16/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=2, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4340\n",
            "\n",
            "validation prompt 3: QWK: 0.4866\n",
            "\n",
            "validation prompt 4: QWK: 0.5454\n",
            "\n",
            "validation prompt 5: early stop at epoch 11 QWK: 0.2709\n",
            "\n",
            "validation prompt 6: QWK: 0.1176\n",
            "\n",
            "validation prompt 7: QWK: 0.5229\n",
            "\n",
            "validation prompt 8: early stop at epoch 13 QWK: 0.4313\n",
            "\n",
            "Average QWK for this combination: 0.4012\n",
            "\n",
            "--------------- testing combination 17/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=2, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 8 QWK: 0.3703\n",
            "\n",
            "validation prompt 3: early stop at epoch 7 QWK: 0.4843\n",
            "\n",
            "validation prompt 4: QWK: 0.4857\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0273\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0681\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.3370\n",
            "\n",
            "validation prompt 8: early stop at epoch 11 QWK: 0.4463\n",
            "\n",
            "Average QWK for this combination: 0.3170\n",
            "\n",
            "--------------- testing combination 18/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=2, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 19/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=4, lr=0.001\n",
            "\n",
            "validation prompt 1: early stop at epoch 14 QWK: 0.4762\n",
            "\n",
            "validation prompt 3: QWK: 0.5129\n",
            "\n",
            "validation prompt 4: QWK: 0.5388\n",
            "\n",
            "validation prompt 5: QWK: 0.2448\n",
            "\n",
            "validation prompt 6: QWK: 0.1283\n",
            "\n",
            "validation prompt 7: QWK: 0.5405\n",
            "\n",
            "validation prompt 8: early stop at epoch 11 QWK: 0.3986\n",
            "\n",
            "Average QWK for this combination: 0.4057\n",
            "\n",
            "--------------- testing combination 20/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=4, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 14 QWK: 0.3513\n",
            "\n",
            "validation prompt 3: early stop at epoch 7 QWK: 0.5136\n",
            "\n",
            "validation prompt 4: early stop at epoch 7 QWK: 0.5458\n",
            "\n",
            "validation prompt 5: early stop at epoch 7 QWK: 0.0653\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0353\n",
            "\n",
            "validation prompt 7: early stop at epoch 6 QWK: 0.3752\n",
            "\n",
            "validation prompt 8: early stop at epoch 8 QWK: 0.5724\n",
            "\n",
            "Average QWK for this combination: 0.3513\n",
            "\n",
            "--------------- testing combination 21/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=4, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 22/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=8, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4463\n",
            "\n",
            "validation prompt 3: early stop at epoch 11 QWK: 0.5105\n",
            "\n",
            "validation prompt 4: early stop at epoch 14 QWK: 0.5517\n",
            "\n",
            "validation prompt 5: QWK: 0.2274\n",
            "\n",
            "validation prompt 6: early stop at epoch 13 QWK: 0.0936\n",
            "\n",
            "validation prompt 7: early stop at epoch 13 QWK: 0.5673\n",
            "\n",
            "validation prompt 8: QWK: 0.4711\n",
            "\n",
            "Average QWK for this combination: 0.4097\n",
            "\n",
            "--------------- testing combination 23/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=8, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 4 QWK: 0.3743\n",
            "\n",
            "validation prompt 3: early stop at epoch 7 QWK: 0.5137\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.5313\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.1025\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0582\n",
            "\n",
            "validation prompt 7: early stop at epoch 10 QWK: 0.3450\n",
            "\n",
            "validation prompt 8: early stop at epoch 9 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.2750\n",
            "\n",
            "--------------- testing combination 24/36--------------\n",
            "hyperparams: units per layer D=16, num of layers k=8, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 25/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=1, lr=0.001\n",
            "\n",
            "validation prompt 1: early stop at epoch 15 QWK: 0.4134\n",
            "\n",
            "validation prompt 3: QWK: 0.4907\n",
            "\n",
            "validation prompt 4: QWK: 0.5135\n",
            "\n",
            "validation prompt 5: QWK: 0.2775\n",
            "\n",
            "validation prompt 6: early stop at epoch 12 QWK: 0.1298\n",
            "\n",
            "validation prompt 7: QWK: 0.5803\n",
            "\n",
            "validation prompt 8: QWK: 0.3777\n",
            "\n",
            "Average QWK for this combination: 0.3975\n",
            "\n",
            "--------------- testing combination 26/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=1, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 9 QWK: 0.3329\n",
            "\n",
            "validation prompt 3: early stop at epoch 9 QWK: 0.4185\n",
            "\n",
            "validation prompt 4: QWK: 0.4609\n",
            "\n",
            "validation prompt 5: early stop at epoch 8 QWK: 0.0860\n",
            "\n",
            "validation prompt 6: early stop at epoch 7 QWK: 0.0299\n",
            "\n",
            "validation prompt 7: QWK: 0.3257\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.4344\n",
            "\n",
            "Average QWK for this combination: 0.2984\n",
            "\n",
            "--------------- testing combination 27/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=1, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 28/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=2, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.5026\n",
            "\n",
            "validation prompt 3: early stop at epoch 12 QWK: 0.4985\n",
            "\n",
            "validation prompt 4: QWK: 0.5436\n",
            "\n",
            "validation prompt 5: QWK: 0.3155\n",
            "\n",
            "validation prompt 6: early stop at epoch 14 QWK: 0.1061\n",
            "\n",
            "validation prompt 7: QWK: 0.6007\n",
            "\n",
            "validation prompt 8: QWK: 0.4331\n",
            "\n",
            "Average QWK for this combination: 0.4286\n",
            "BEST COMBO SO FAR! =)\n",
            "\n",
            "--------------- testing combination 29/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=2, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.3418\n",
            "\n",
            "validation prompt 3: early stop at epoch 13 QWK: 0.4891\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.5022\n",
            "\n",
            "validation prompt 5: early stop at epoch 6 QWK: 0.0273\n",
            "\n",
            "validation prompt 6: early stop at epoch 11 QWK: 0.0182\n",
            "\n",
            "validation prompt 7: early stop at epoch 8 QWK: 0.3372\n",
            "\n",
            "validation prompt 8: early stop at epoch 9 QWK: 0.4680\n",
            "\n",
            "Average QWK for this combination: 0.3120\n",
            "\n",
            "--------------- testing combination 30/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=2, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 31/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=4, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4858\n",
            "\n",
            "validation prompt 3: QWK: 0.4886\n",
            "\n",
            "validation prompt 4: QWK: 0.5398\n",
            "\n",
            "validation prompt 5: early stop at epoch 10 QWK: 0.2378\n",
            "\n",
            "validation prompt 6: early stop at epoch 11 QWK: 0.0930\n",
            "\n",
            "validation prompt 7: QWK: 0.5690\n",
            "\n",
            "validation prompt 8: QWK: 0.4728\n",
            "\n",
            "Average QWK for this combination: 0.4124\n",
            "\n",
            "--------------- testing combination 32/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=4, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 13 QWK: 0.3689\n",
            "\n",
            "validation prompt 3: early stop at epoch 4 QWK: 0.5120\n",
            "\n",
            "validation prompt 4: early stop at epoch 9 QWK: 0.5435\n",
            "\n",
            "validation prompt 5: early stop at epoch 9 QWK: 0.0729\n",
            "\n",
            "validation prompt 6: early stop at epoch 8 QWK: 0.0517\n",
            "\n",
            "validation prompt 7: early stop at epoch 13 QWK: 0.3524\n",
            "\n",
            "validation prompt 8: early stop at epoch 11 QWK: 0.5325\n",
            "\n",
            "Average QWK for this combination: 0.3477\n",
            "\n",
            "--------------- testing combination 33/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=4, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------- testing combination 34/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=8, lr=0.001\n",
            "\n",
            "validation prompt 1: QWK: 0.4703\n",
            "\n",
            "validation prompt 3: QWK: 0.4746\n",
            "\n",
            "validation prompt 4: QWK: 0.5103\n",
            "\n",
            "validation prompt 5: QWK: 0.2285\n",
            "\n",
            "validation prompt 6: early stop at epoch 10 QWK: 0.0864\n",
            "\n",
            "validation prompt 7: QWK: 0.5338\n",
            "\n",
            "validation prompt 8: early stop at epoch 12 QWK: 0.4754\n",
            "\n",
            "Average QWK for this combination: 0.3970\n",
            "\n",
            "--------------- testing combination 35/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=8, lr=0.01\n",
            "\n",
            "validation prompt 1: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 7 QWK: 0.5376\n",
            "\n",
            "validation prompt 5: early stop at epoch 8 QWK: 0.0677\n",
            "\n",
            "validation prompt 6: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 6 QWK: 0.4145\n",
            "\n",
            "validation prompt 8: early stop at epoch 4 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.1457\n",
            "\n",
            "--------------- testing combination 36/36--------------\n",
            "hyperparams: units per layer D=32, num of layers k=8, lr=0.1\n",
            "\n",
            "validation prompt 1: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "validation prompt 3: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 4: early stop at epoch 7 QWK: 0.0000\n",
            "\n",
            "validation prompt 5: early stop at epoch 7 QWK: 0.0000\n",
            "\n",
            "validation prompt 6: early stop at epoch 8 QWK: 0.0000\n",
            "\n",
            "validation prompt 7: early stop at epoch 6 QWK: 0.0000\n",
            "\n",
            "validation prompt 8: early stop at epoch 5 QWK: 0.0000\n",
            "\n",
            "Average QWK for this combination: 0.0000\n",
            "\n",
            "--------------------------------------------------\n",
            "---------------- FINISHED GRID SEARCH ----------------\n",
            "mins taken:(139.21 mins)\n",
            "best hyperparam combo: {'hidden_unit': 32, 'num_layers': 2, 'learning_rate': 0.001} with best average QWK: 0.4286\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Batch Size Optimization"
      ],
      "metadata": {
        "id": "-KZCdpuv4wtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------Batch size optimization-----------------------------------------------\n",
        "# change depending on target and chosen validation prompt\n",
        "ranges = [1,3,4,5,6,7]\n",
        "VALIDATION_PROMPT_ID = 8\n",
        "\n",
        "print(f\"\\n{'-'*50}\")\n",
        "print(\"Starting batch size optimization with the best parameters\")\n",
        "print(f\"{'-'*50}\\n\")\n",
        "\n",
        "# we will 6 prompts a training set (~85%) and 1 for validation (~15%)\n",
        "train_filter = (data['prompt_ids'] != TEST_PROMPT_ID) & (data['prompt_ids'] != VALIDATION_PROMPT_ID)\n",
        "val_filter = data['prompt_ids'] == VALIDATION_PROMPT_ID\n",
        "\n",
        "#preparing the training data\n",
        "X_train = torch.FloatTensor(data['features'][train_filter])\n",
        "y_train_orig = torch.FloatTensor(data['holistic'][train_filter])\n",
        "prompt_ids_train = data['prompt_ids'][train_filter]\n",
        "\n",
        "#preparing the validation data (prompt 8)\n",
        "X_val = torch.FloatTensor(data['features'][val_filter])\n",
        "y_val_orig = torch.FloatTensor(data['holistic'][val_filter])\n",
        "\n",
        "print(\"Dataset after separation:\")\n",
        "print(f\"Training: {len(X_train)} essays (prompts {ranges})\")\n",
        "print(f\"Validation: {len(X_val)} essays (prompt {VALIDATION_PROMPT_ID})\")\n",
        "print(f\"Held out: Prompt {TEST_PROMPT_ID} (for final testing)\\n\")\n",
        "\n",
        "#normalizing the training scores separatly for each prompt\n",
        "y_train = torch.zeros_like(y_train_orig)\n",
        "for prompt_id in ranges:\n",
        "    prompt_filter = prompt_ids_train == prompt_id\n",
        "    y_train[prompt_filter] = normalize_scores(y_train_orig[prompt_filter], prompt_id)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "#normalizing the validation scores\n",
        "y_val = normalize_scores(y_val_orig, VALIDATION_PROMPT_ID)\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "\n",
        "#batch sizes to test for optimization\n",
        "batch_sizes = [4, 8, 16, 32]\n",
        "print(f\"Testing batch sizes: {batch_sizes}\")\n",
        "\n",
        "#Intializing the variables to track the best batch size\n",
        "best_batch_qwk = -1\n",
        "best_batch_size = None\n",
        "batch_start_time = time.time()\n",
        "\n",
        "# Testing for each batch size and evaluating its preformance\n",
        "for batch_size in batch_sizes:\n",
        "    print(f\"\\nTesting batch size: {batch_size}\")\n",
        "\n",
        "# Initializing the model with the best parameters from grid search\n",
        "    model = NeuralNetwork(\n",
        "        input_size=86,\n",
        "        hidden_unit=best_params['hidden_unit'],\n",
        "        num_layers=best_params['num_layers']\n",
        "    )\n",
        "#Setting up the optimizer with Adamw\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=best_params['learning_rate'],\n",
        "        betas=(0.9, 0.999),\n",
        "        weight_decay=0.1\n",
        "    )\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "# Training loop for 15 epochs or until early stopping\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Processing the training data in batches\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_X = X_train[i:i + batch_size]\n",
        "            batch_y = y_train[i:i + batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / num_batches\n",
        "\n",
        "        # Calculating the validation loss\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "        # Early stopping we stop the training if  the validation loss doesn't improve for 3 epochs\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= 3:\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch + 1}/15 - Train Loss: {avg_epoch_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "    # Calculating the validation loss after every epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_pred = model(X_val)\n",
        "        val_pred_denorm = denormalize_scores(val_pred.numpy(), VALIDATION_PROMPT_ID)\n",
        "        val_true_denorm = y_val_orig.numpy()\n",
        "\n",
        "        # Calculating the QWK\n",
        "        qwk = quadratic_weighted_kappa(\n",
        "            val_true_denorm.round(),\n",
        "            val_pred_denorm.flatten()\n",
        "        )\n",
        "        print(f\"Validation QWK: {qwk:.4f}\")\n",
        "\n",
        "        if qwk > best_batch_qwk:\n",
        "            best_batch_qwk = qwk\n",
        "            best_batch_size = batch_size\n",
        "            print(\"New best batch size found!!!!! :)\")\n",
        "\n",
        "batch_time = time.time() - batch_start_time\n",
        "print(f\"\\n{'-'*50}\")\n",
        "print(\"Done with batch size optimization \")\n",
        "print(f\"Time taken: {batch_time:.2f} seconds ({batch_time/60:.2f} minutes)\")\n",
        "print(f\"Best batch size: {best_batch_size}\")\n",
        "print(f\"Best validation QWK: {best_batch_qwk:.4f}\")\n",
        "print(f\"{'-'*50}\\n\")"
      ],
      "metadata": {
        "id": "N4I3VAsa2L1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d34bb2-832d-4060-9a08-064df1eb4da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Starting batch size optimization with the best parameters\n",
            "--------------------------------------------------\n",
            "\n",
            "Dataset after separation:\n",
            "Training: 10455 essays (prompts [1, 3, 4, 5, 6, 7])\n",
            "Validation: 723 essays (prompt 8)\n",
            "Held out: Prompt 2 (for final testing)\n",
            "\n",
            "Testing batch sizes: [4, 8, 16, 32]\n",
            "\n",
            "Testing batch size: 4\n",
            "Epoch 5/15 - Train Loss: 0.022807, Val Loss: 0.023835\n",
            "Early stopping at epoch 7\n",
            "Validation QWK: 0.4154\n",
            "New best batch size found!!!!! :)\n",
            "\n",
            "Testing batch size: 8\n",
            "Early stopping at epoch 4\n",
            "Validation QWK: 0.3813\n",
            "\n",
            "Testing batch size: 16\n",
            "Early stopping at epoch 4\n",
            "Validation QWK: 0.5485\n",
            "New best batch size found!!!!! :)\n",
            "\n",
            "Testing batch size: 32\n",
            "Epoch 5/15 - Train Loss: 0.022729, Val Loss: 0.014503\n",
            "Early stopping at epoch 8\n",
            "Validation QWK: 0.4987\n",
            "\n",
            "--------------------------------------------------\n",
            "Done with batch size optimization \n",
            "Time taken: 37.68 seconds (0.63 minutes)\n",
            "Best batch size: 16\n",
            "Best validation QWK: 0.5485\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7. Final model training and testing"
      ],
      "metadata": {
        "id": "5Mqc7KYx48OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have finalized all our hyperparameters that we will use to train the model\n",
        "final_params = best_params.copy()\n",
        "final_params['batch_size'] = best_batch_size\n",
        "\n",
        "#retrain on the whole data again except on prompt 1\n",
        "final_train_filter = data['prompt_ids'] != TEST_PROMPT_ID\n",
        "X_final_train = torch.FloatTensor(data['features'][final_train_filter])\n",
        "y_final_train_orig = torch.FloatTensor(data['holistic'][final_train_filter])\n",
        "prompt_ids_final = data['prompt_ids'][final_train_filter]\n",
        "\n",
        "#normalize scores again the same way we did before for the final training\n",
        "y_final_train = torch.zeros_like(y_final_train_orig)\n",
        "for prompt_id in TRAIN_PROMPT_RANGE:\n",
        "    prompt_filter = prompt_ids_final == prompt_id\n",
        "    y_final_train[prompt_filter] = normalize_scores(y_final_train_orig[prompt_filter], prompt_id)\n",
        "y_final_train = y_final_train.reshape(-1, 1)\n",
        "\n",
        "#initialize the final model with the best hyperparameters\n",
        "final_model = NeuralNetwork(\n",
        "    input_size=86,\n",
        "    hidden_unit=final_params['hidden_unit'],\n",
        "    num_layers=final_params['num_layers']\n",
        ")\n",
        "#initialize the optimizer with AdamW and MSE loss function\n",
        "optimizer = torch.optim.AdamW(\n",
        "    final_model.parameters(),\n",
        "    lr=final_params['learning_rate'],\n",
        "    betas=(0.9, 0.999),\n",
        "    weight_decay=0.1\n",
        ")\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "#train the final model on the entire training set now\n",
        "for epoch in range(15):\n",
        "    final_model.train()\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for i in range(0, len(X_final_train), final_params['batch_size']):\n",
        "        start, end = i, i + final_params['batch_size']\n",
        "        batch_X = X_final_train[start:end] #get a batch of features then get the corresponding scores too\n",
        "        batch_y = y_final_train[start:end]\n",
        "\n",
        "        optimizer.zero_grad() #set the gradients to zero\n",
        "        outputs = final_model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step() #updating the weights\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "#test on heldout prompt\n",
        "test_filter = data['prompt_ids'] == TEST_PROMPT_ID\n",
        "X_test = torch.FloatTensor(data['features'][test_filter])\n",
        "y_test = torch.FloatTensor(data['holistic'][test_filter])\n",
        "\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_pred = final_model(X_test)\n",
        "    test_pred_denorm = denormalize_scores(test_pred.numpy(), TEST_PROMPT_ID)\n",
        "\n",
        "    test_qwk = quadratic_weighted_kappa(\n",
        "        y_test.numpy().round(),\n",
        "        test_pred_denorm.flatten()\n",
        "    )\n",
        "\n",
        "print(f\"\\n{'-'*50}\")\n",
        "print(f\"Results on testing set (Prompt {TEST_PROMPT_ID}):\")\n",
        "print(f\"final QWK: {test_qwk:.4f}\")\n",
        "print(f\"Final parameters: {final_params}\")\n",
        "print(f\"{'-'*50}\\n\")\n",
        "\n",
        "final_params, test_qwk = best_params, test_qwk"
      ],
      "metadata": {
        "id": "8pCxJ7t52OaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859f223c-f16b-4094-e346-00e4d1cf0eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Results on testing set (Prompt 2):\n",
            "final QWK: 0.6176\n",
            "Final parameters: {'hidden_unit': 32, 'num_layers': 2, 'learning_rate': 0.001, 'batch_size': 16}\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = torch.jit.script(final_model)\n",
        "scripted_model.save(\"model-A-2.pt\")"
      ],
      "metadata": {
        "id": "1e74JZctSuqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}